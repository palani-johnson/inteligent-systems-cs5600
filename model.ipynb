{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Description \n","This notebook contains a basic implementation of a Keras UNet model for the [Sartorius - Cell Instance Segmentation competition](https://www.kaggle.com/c/sartorius-cell-instance-segmentation/data). If you wish to run an inference and submit, only export your model using [tf.keras.callbacks.ModelCheckpoint()](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint). Then you can create a private dataset containing the model, load the model and make the predictions for the test set in another notebook (internet should be inactivated in notebook settings).\n","\n","## Problem definition\n","Data: \n","\n","[Phase-contrast microscopy](https://en.wikipedia.org/wiki/Phase-contrast_microscopy) images of human neuronal cell  along with annotations (labels) representing cell segmentations. \n","\n","Aim: \n","\n","The trained model should be able to predict the annotations for cell segmentation, including rare cell types (such as neuroblastoma cell line SH-SY5Y as discussed in the [competition description](https://www.kaggle.com/c/sartorius-cell-instance-segmentation/overview)). Annotations should be provided in run-length format (see functions rle_decode() and rle_encode below).\n","\n","## Approach \n","[U-Net](https://en.wikipedia.org/wiki/U-Net) as implemented in reference notebook 2. \n","\n","\"The model being used here is a modified U-Net. A U-Net consists of an encoder (downsampler) and decoder (upsampler). In-order to learn robust features and reduce the number of trainable parameters, you will use a pretrained model - MobileNetV2 - as the encoder. For the decoder, you will use the upsample block, which is already implemented in the pix2pix example in the TensorFlow Examples repo. (Check out the pix2pix: Image-to-image translation with a conditional GAN tutorial in a notebook.)\n","\n","As mentioned, the encoder will be a pretrained MobileNetV2 model which is prepared and ready to use in tf.keras.applications. The encoder consists of specific outputs from intermediate layers in the model. Note that the encoder will not be trained during the training process.\n","\n","The decoder/upsampler is simply a series of upsample blocks implemented in TensorFlow examples.\" [Tensorflow Tutorials: Image segmentation ](https://www.tensorflow.org/tutorials/images/segmentation).  \n","\n","Reference notebooks:\n","1. [Sartorius Competition Training Keras UNet](https://www.kaggle.com/aramos/sartorius-competition-training-keras-unet).\n","\n","Other references: \n","1. [Tensorflow Tutorials: Image segmentation ](https://www.tensorflow.org/tutorials/images/segmentation).\n","2. [pix2pix: Image-to-image translation with a conditional GAN](https://www.tensorflow.org/tutorials/generative/pix2pix?hl=nb).\n"]},{"cell_type":"markdown","metadata":{},"source":["## Workflow\n","\n","[1. Libraries and paths](#section-1)\n","\n","[2. Functions](#section-2)\n","\n","[3. Constants](#section-3)\n","\n","[4. Generate train and validation data sets](#section-4)\n","\n","[5. Define the model](#section-5)\n","\n","[6. Training](#section-6)\n","\n","[7. Test set predictions](#section-7)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"section-1\"></a>\n","### 1. Libraries and paths"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-12-16T19:03:59.234618Z","iopub.status.busy":"2021-12-16T19:03:59.234262Z","iopub.status.idle":"2021-12-16T19:04:04.492908Z","shell.execute_reply":"2021-12-16T19:04:04.492135Z","shell.execute_reply.started":"2021-12-16T19:03:59.234526Z"},"trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np \n","import pandas as pd\n","import os\n","from pathlib import Path\n","import cv2\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers.experimental import preprocessing\n","\n","from IPython.display import clear_output\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T19:04:04.496377Z","iopub.status.busy":"2021-12-16T19:04:04.495843Z","iopub.status.idle":"2021-12-16T19:04:04.501664Z","shell.execute_reply":"2021-12-16T19:04:04.500937Z","shell.execute_reply.started":"2021-12-16T19:04:04.496336Z"},"trusted":true},"outputs":[],"source":["# input\n","DIR = './data/sartorius-cell-instance-segmentation'\n","train_csv = os.path.join(DIR,'train.csv') \n","train_path =  os.path.join(DIR, 'train/')\n","test_path = os.path.join(DIR, 'test/')\n","\n","# output \n","OUTPUT = './data/project2-models'\n","csv_output = os.path.join(OUTPUT, 'submission.csv') \n","model_output = os.path.join(OUTPUT, 'unet_keras_model.h5')"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"section-2\"></a>\n","### 2. Functions"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T19:04:04.503402Z","iopub.status.busy":"2021-12-16T19:04:04.502943Z","iopub.status.idle":"2021-12-16T19:04:04.523633Z","shell.execute_reply":"2021-12-16T19:04:04.523002Z","shell.execute_reply.started":"2021-12-16T19:04:04.503365Z"},"trusted":true},"outputs":[],"source":["def rle_decode(mask_rle, shape, color=1):\n","    '''\n","    mask_rle: run-length as string formated (start length)\n","    shape: (height,width) of array to return \n","    Returns numpy array, 1 - mask, 0 - background.\n","    ref: https://www.kaggle.com/inversion/run-length-decoding-quick-start\n","    '''\n","    s = mask_rle.split()\n","    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n","    starts -= 1\n","    ends = starts + lengths\n","    img = np.zeros((shape[0] * shape[1]), dtype=np.float32)\n","    for lo, hi in zip(starts, ends):\n","        img[lo : hi] = color\n","    return img.reshape(shape)\n","\n","\n","def rle_encode(img):\n","    '''\n","    img: numpy array, 1 - mask, 0 - background\n","    Returns run length as string formated\n","    ref: https://www.kaggle.com/dragonzhang/positive-score-with-detectron-3-3-inference\n","    '''\n","    pixels = img.flatten()\n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)\n","\n","\n","def get_mask(image_id, df):\n","    '''\n","    Uses rle_decode() to get ndarray from mask using image_id in dataframe (df).\n","    ref: https://www.kaggle.com/barteksadlej123/sartors-tf-starter\n","    '''\n","    current = df[df[\"id\"] == image_id]\n","    labels = current[\"annotation\"].tolist()\n","    \n","    mask = np.zeros((HEIGHT, WIDTH))\n","    for label in labels:\n","        mask += rle_decode(label, (HEIGHT, WIDTH))\n","    mask = mask.clip(0, 1)\n","    \n","    return mask\n","\n","\n","#  fix overlaps: \n","\n","def check_overlap(msk):\n","    '''\n","    Checks if there are overlap in a mask (msk).\n","    ref: https://www.kaggle.com/awsaf49/sartorius-fix-overlap\n","    '''\n","    msk = msk.astype(np.bool).astype(np.uint8)\n","    return np.any(np.sum(msk, axis=-1)>1)\n","\n","\n","def fix_overlap(msk):\n","    '''\n","    Args:\n","        mask: multi-channel mask, each channel is an instance of cell, shape:(520,704,None)\n","    Returns:\n","        multi-channel mask with non-overlapping values, shape:(520,704,None) \n","    ref: https://www.kaggle.com/awsaf49/sartorius-fix-overlap\n","    '''\n","    msk = np.array(msk)\n","    msk = np.pad(msk, [[0,0],[0,0],[1,0]])\n","    ins_len = msk.shape[-1]\n","    msk = np.argmax(msk,axis=-1)\n","    msk = tf.keras.utils.to_categorical(msk, num_classes=ins_len)\n","    msk = msk[...,1:]\n","    msk = msk[...,np.any(msk, axis=(0,1))]\n","    return msk\n","\n","\n","# make predictions for test set: \n","\n","def make_predictions(dataset, num, keras_model):\n","    '''\n","    For a tf.Dataset, makes predictions for n=num (num =-1 or all_images takes all images in the dataset), \n","    images using a keras_model. Returns a list of predicted masks, each as ndarray. \n","    '''\n","    predictions = []\n","    if dataset:\n","        for image in dataset.take(num):\n","            image = image[None]\n","            pred_mask = keras_model.predict(image)\n","            # changes shape from (1,512,512,1) to (512,512)\n","            pred_mask = pred_mask[0, :, :, 0]\n","            # fix overlaps\n","            if check_overlap(msk=pred_mask)==True:\n","                pred_mask = pred_mask[None]\n","                pred_mask = fix_overlap(msk=pred_mask)\n","            # transforms ndarray values to 0s and 1s\n","            pred_mask =  np.where( pred_mask > 0.5, 1, 0)\n","            predictions.append(pred_mask)\n","    return predictions"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"section-3\"></a>\n","### 3. Constants "]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T19:04:04.526284Z","iopub.status.busy":"2021-12-16T19:04:04.525804Z","iopub.status.idle":"2021-12-16T19:04:04.534777Z","shell.execute_reply":"2021-12-16T19:04:04.534057Z","shell.execute_reply.started":"2021-12-16T19:04:04.526223Z"},"trusted":true},"outputs":[],"source":["DEBUG = False\n","\n","SEED = 123\n","WIDTH, HEIGHT = 704, 520\n","RESIZE_WIDTH, RESIZE_HEIGHT = 512, 512\n","BATCH_SIZE = 16\n","BUFFER_SIZE = 32\n","\n","VAL_SPLIT = 0.2\n","\n","AUTO = tf.data.AUTOTUNE\n","\n","EPOCHS = 20"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"section-4\"></a>\n","### 4. Generate train and validation data sets"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T19:04:04.536578Z","iopub.status.busy":"2021-12-16T19:04:04.536302Z","iopub.status.idle":"2021-12-16T19:04:12.621874Z","shell.execute_reply":"2021-12-16T19:04:12.62118Z","shell.execute_reply.started":"2021-12-16T19:04:04.536545Z"},"trusted":true},"outputs":[],"source":["# train and validation split\n","train = pd.read_csv(train_csv)\n","train.head()\n","\n","n_ids = train.id.nunique()\n","\n","if DEBUG:\n","    unique_ids_train = list(set(train['id'].tolist()))[:BATCH_SIZE]\n","    unique_ids_valid = list(set(train['id'].tolist()))[BATCH_SIZE:2*BATCH_SIZE]\n","else:\n","    unique_ids_train = list(set(train['id'].tolist()))[:int(n_ids * (1 - VAL_SPLIT))]\n","    unique_ids_valid = list(set(train['id'].tolist()))[int(n_ids * (1 - VAL_SPLIT)):]\n","\n","\n","temp = pd.DataFrame()\n","for sample_id in unique_ids_train:\n","    query = train[train.id == sample_id]\n","    temp = pd.concat([temp, query])\n","train = temp\n","train = train.reset_index(drop=True)\n","\n","temp = pd.DataFrame()\n","for sample_id in unique_ids_valid:\n","    query = train[train.id == sample_id]\n","    temp = pd.concat([temp, query])\n","valid = temp\n","valid = train.reset_index(drop=True)\n","    \n","TRAIN_LENGTH = train['id'].nunique()\n","STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n","\n","VALID_LENGTH = valid['id'].nunique()\n","VALIDATION_STEPS = VALID_LENGTH // BATCH_SIZE"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T19:04:12.623243Z","iopub.status.busy":"2021-12-16T19:04:12.622989Z","iopub.status.idle":"2021-12-16T19:04:12.6305Z","shell.execute_reply":"2021-12-16T19:04:12.629499Z","shell.execute_reply.started":"2021-12-16T19:04:12.623208Z"},"trusted":true},"outputs":[],"source":["# training data generator \n","def train_generator(df):\n","    image_ids = set(df['id'].tolist())\n","    \n","    for image_id in image_ids:\n","        image = cv2.imread(os.path.join(train_path, image_id) + '.png') \n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        \n","        mask = get_mask(image_id, df)\n","        \n","        image = cv2.resize(image, (RESIZE_HEIGHT, RESIZE_WIDTH))\n","        mask = cv2.resize(mask, (RESIZE_HEIGHT, RESIZE_WIDTH))\n","        mask = mask.reshape((*mask.shape, 1))\n","        \n","        image = image.astype(np.float32)\n","        mask = mask.astype(np.int32)\n","        \n","        yield image, mask"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T19:04:12.632278Z","iopub.status.busy":"2021-12-16T19:04:12.631622Z","iopub.status.idle":"2021-12-16T19:04:15.051127Z","shell.execute_reply":"2021-12-16T19:04:15.050408Z","shell.execute_reply.started":"2021-12-16T19:04:12.632236Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2021-12-16 13:56:48.881701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-16 13:56:48.963856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-16 13:56:48.964154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-16 13:56:48.965444: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-12-16 13:56:48.966615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-16 13:56:48.966912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-16 13:56:48.967161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-16 13:56:49.720562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-16 13:56:49.721000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-16 13:56:49.721316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-16 13:56:49.721604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14787 MB memory:  -> device: 0, name: Quadro RTX 5000 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"]}],"source":["# use the generator to get training and validation sets\n","train_ds = tf.data.Dataset.from_generator(\n","    lambda : train_generator(train), \n","    output_types=(tf.float32, tf.int32),\n","    output_shapes=((RESIZE_HEIGHT, RESIZE_WIDTH, 3), (RESIZE_HEIGHT, RESIZE_WIDTH, 1)))\n","\n","valid_ds = tf.data.Dataset.from_generator(\n","    lambda : train_generator(valid), \n","    output_types=(tf.float32, tf.int32),\n","    output_shapes=((RESIZE_HEIGHT, RESIZE_WIDTH, 3), (RESIZE_HEIGHT, RESIZE_WIDTH, 1)))\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T19:04:15.053033Z","iopub.status.busy":"2021-12-16T19:04:15.052517Z","iopub.status.idle":"2021-12-16T19:04:15.059612Z","shell.execute_reply":"2021-12-16T19:04:15.058865Z","shell.execute_reply.started":"2021-12-16T19:04:15.052987Z"},"trusted":true},"outputs":[],"source":["# \"the following class performs a simple augmentation by randomly-flipping an image\"\n","class Augment(tf.keras.layers.Layer):\n","    def __init__(self, seed=SEED):\n","        super().__init__()\n","        \n","        self.augment_inputs = preprocessing.RandomFlip('horizontal', seed=seed)\n","        self.augment_labels = preprocessing.RandomFlip('horizontal', seed=seed)\n","        \n","    def call(self, inputs, labels):\n","        inputs = self.augment_inputs(inputs)\n","        labels = self.augment_labels(labels)\n","        return inputs, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T19:04:15.061267Z","iopub.status.busy":"2021-12-16T19:04:15.061025Z","iopub.status.idle":"2021-12-16T19:04:15.218817Z","shell.execute_reply":"2021-12-16T19:04:15.218146Z","shell.execute_reply.started":"2021-12-16T19:04:15.061231Z"},"trusted":true},"outputs":[],"source":["# \"build the input pipeline, applying the augmentation after batching the inputs\"\n","\n","train_ds = (\n","    train_ds\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE)\n","    .repeat()\n","    .map(Augment())\n","    .prefetch(AUTO))\n","\n","valid_ds = (\n","    valid_ds\n","    .batch(BATCH_SIZE)\n","    .repeat()\n","    .prefetch(AUTO))"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"section-5\"></a>\n","### 5. Define the model "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T19:04:15.222066Z","iopub.status.busy":"2021-12-16T19:04:15.221509Z","iopub.status.idle":"2021-12-16T19:04:22.449614Z","shell.execute_reply":"2021-12-16T19:04:22.448798Z","shell.execute_reply.started":"2021-12-16T19:04:15.222028Z"},"trusted":true},"outputs":[],"source":["# \"visualize an image example and its corresponding mask from the dataset\"\n","\n","def display(display_list):\n","    plt.figure(figsize=(20, 20))\n","\n","    title = ['Input Image', 'True Mask', 'Predicted Mask']\n","\n","    for i in range(len(display_list)):\n","        plt.subplot(1, len(display_list), i+1)\n","        plt.title(title[i])\n","        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n","        plt.axis('off')\n","    plt.show()\n","    \n","for images, masks in train_ds.take(2):\n","    sample_image, sample_mask = images[0], masks[0]\n","    display([sample_image, sample_mask])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T19:05:23.230201Z","iopub.status.busy":"2021-12-16T19:05:23.22994Z","iopub.status.idle":"2021-12-16T19:05:23.271105Z","shell.execute_reply":"2021-12-16T19:05:23.270019Z","shell.execute_reply.started":"2021-12-16T19:05:23.230173Z"},"trusted":true},"outputs":[],"source":["def get_model():\n","    from keras import layers\n","    \n","    model = keras.models.Sequential(\n","        [\n","            layers.Conv2D(\n","                16, (16, 16), padding=\"same\", activation=\"relu\", input_shape=(RESIZE_HEIGHT, RESIZE_WIDTH, 3)\n","            ),\n","            layers.MaxPooling2D((4, 4)),\n","            layers.Conv2D(4, (4, 4), padding=\"same\", activation=\"relu\"),\n","            layers.MaxPooling2D((4, 4)),\n","            layers.Flatten(),\n","            layers.Dense(\n","                64,\n","                activation=\"relu\",\n","                kernel_regularizer=keras.regularizers.l2(0.001),\n","            ),\n","            layers.Dropout(0.3),\n","            layers.Dense(RESIZE_HEIGHT * RESIZE_WIDTH, activation=\"softmax\"),\n","            layers.Reshape((RESIZE_HEIGHT, RESIZE_WIDTH, 1))\n","        ]\n","    )\n","    opt = keras.optimizers.Adam(learning_rate=0.001)\n","    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","    return model\n","\n","\n","model = get_model()\n","\n","# visualize model architecture \n","tf.keras.utils.plot_model(model, show_shapes=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T18:54:50.326496Z","iopub.status.busy":"2021-12-16T18:54:50.325708Z"},"trusted":true},"outputs":[],"source":["# try out the model to check what it predicts before training\n","\n","def create_mask(pred_mask):\n","    pred_mask = tf.where(pred_mask > 0.5,1,0)\n","    return pred_mask\n","\n","\n","def show_predictions(dataset=None, num=1):\n","    if dataset:\n","        for image, mask in dataset.take(num):\n","            pred_mask = model.predict(image)\n","            display([image[0], mask[0], create_mask(pred_mask[0])])\n","    else:\n","        display([sample_image, sample_mask,\n","                 create_mask(model.predict(sample_image[tf.newaxis, ...])[0])])\n","\n","        \n","show_predictions(train_ds)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"section-6\"></a>\n","### 6. Training"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# training\n","\n","# \"observe how the model improves while it is training\"\n","class DisplayCallback(tf.keras.callbacks.Callback):\n","    def __init__(self):\n","        super().__init__()\n","    def on_epoch_end(self, epoch, logs=None):\n","        clear_output(wait=False)\n","        show_predictions()\n","        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n","# display callback defined above\n","display_cb = DisplayCallback()\n","\n","# \"save the Keras model or model weights at some frequency\"\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","    model_output,\n","    save_best_only=True,\n","    save_weights_only=True,\n",")\n","\n","# \"reduce learning rate when a metric has stopped improving\"\n","# documentation: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau\n","lr_reduce = tf.keras.callbacks.ReduceLROnPlateau( monitor='val_loss', factor=0.1, patience=10, verbose=0,\n","    mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n","\n","model_history = model.fit(train_ds, epochs=EPOCHS,\n","                          steps_per_epoch=STEPS_PER_EPOCH,\n","                          validation_steps=VALIDATION_STEPS,\n","                          validation_data=valid_ds,\n","                          callbacks=[display_cb, model_checkpoint, lr_reduce])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plot training curve\n","loss = model_history.history['loss']\n","val_loss = model_history.history['val_loss']\n","plt.figure()\n","plt.plot(model_history.epoch, loss, 'r', label='Training loss')\n","plt.plot(model_history.epoch, val_loss, 'bo', label='Validation loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss Value')\n","plt.ylim([0, 1])\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"section-7\"></a>\n","### 7. Test set predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# test data generator \n","test_ids = [  os.path.join(test_path, each)  for each in os.listdir(test_path) if each.endswith('.png')]\n","def test_generator(image_ids):\n","    for image_id in image_ids:\n","        image = cv2.imread(image_id) \n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)        \n","        image = cv2.resize(image, (RESIZE_HEIGHT, RESIZE_WIDTH))\n","        image = image.astype(np.float32)\n","        yield image"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# test dataset from test data generator \n","test_ds = tf.data.Dataset.from_generator(\n","    lambda : test_generator(test_ids), \n","    output_types=(tf.float32),\n","    output_shapes=((RESIZE_HEIGHT, RESIZE_WIDTH, 3)) )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# test image ids and predictions\n","test_predictions = make_predictions(dataset=test_ds, num=len(test_ids), keras_model=model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# encode predections in the RL format\n","test_predictions = [rle_encode(mask) for mask in test_predictions] "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# transform full image paths to ids \n","test_ids = [Path(ID).stem for ID in test_ids]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# generate submission data frame \n","submisssion = pd.DataFrame.from_dict({'id': test_ids, 'predicted': test_predictions} )\n","submisssion = submisssion.sort_values( ['id'], ascending=True )\n","print(submisssion.head(), 'n')\n","submisssion.to_csv(csv_output, index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
